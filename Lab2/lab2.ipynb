{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118193507194519),\n",
       " ('monarch', 0.6189674139022827),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321839332581),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.5181134343147278),\n",
       " ('sultan', 0.5098593831062317),\n",
       " ('monarchy', 0.5087411999702454)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_pretrained = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar words to 'king':\n",
      "  kings: 0.7138\n",
      "  queen: 0.6511\n",
      "  monarch: 0.6413\n",
      "  crown_prince: 0.6204\n",
      "  prince: 0.6160\n",
      "Similar words to 'apple':\n",
      "  apples: 0.7204\n",
      "  pear: 0.6451\n",
      "  fruit: 0.6410\n",
      "  berry: 0.6302\n",
      "  pears: 0.6134\n",
      "Similar words to 'computer':\n",
      "  computers: 0.7979\n",
      "  laptop: 0.6640\n",
      "  laptop_computer: 0.6549\n",
      "  Computer: 0.6473\n",
      "  com_puter: 0.6082\n",
      "Similar words to 'music':\n",
      "  classical_music: 0.7198\n",
      "  jazz: 0.6835\n",
      "  Music: 0.6596\n",
      "  Without_Donny_Kirshner: 0.6416\n",
      "  songs: 0.6396\n",
      "Similar words to 'python':\n",
      "  pythons: 0.6688\n",
      "  Burmese_python: 0.6680\n",
      "  snake: 0.6606\n",
      "  crocodile: 0.6591\n",
      "  boa_constrictor: 0.6444\n"
     ]
    }
   ],
   "source": [
    "words_of_choice = [\"king\", \"apple\", \"computer\", \"music\", \"python\"]\n",
    "for word in words_of_choice:\n",
    "    try:\n",
    "        similar_words = wv_pretrained.most_similar(word, topn=5)\n",
    "        print(f\"Similar words to '{word}':\")\n",
    "        for similar_word, similarity in similar_words:\n",
    "            print(f\"  {similar_word}: {similarity:.4f}\")\n",
    "    except KeyError:\n",
    "        print(f\"'{word}' not in vocabulary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king - man + woman ≈ queen\n",
      "  queen: 0.7118\n",
      "  monarch: 0.6190\n",
      "  princess: 0.5902\n",
      "  crown_prince: 0.5499\n",
      "  prince: 0.5377\n",
      "Paris - France + Germany ≈ Berlin\n",
      "  Berlin: 0.7644\n",
      "  Frankfurt: 0.7330\n",
      "  Dusseldorf: 0.7009\n",
      "  Munich: 0.6774\n",
      "  Cologne: 0.6470\n",
      "Rome - Italy + Japan ≈ Tokyo\n",
      "  Tokyo: 0.6905\n",
      "  Seoul: 0.5483\n",
      "  Toyko: 0.5452\n",
      "  Fukuoka: 0.5432\n",
      "  Nagoya: 0.5394\n",
      "Microsoft - Windows + Apple ≈ Apple_Computer\n",
      "  Apple_Computer: 0.6469\n",
      "  Apple_NSDQ_AAPL: 0.6298\n",
      "  Apple_AAPL: 0.6296\n",
      "  Google: 0.6181\n",
      "  Apple_NASDAQ_AAPL: 0.6131\n"
     ]
    }
   ],
   "source": [
    "analogies = [\n",
    "    (\"king\", \"man\", \"woman\"),\n",
    "    (\"Paris\", \"France\", \"Germany\"),\n",
    "    (\"Rome\", \"Italy\", \"Japan\"),\n",
    "    (\"Microsoft\", \"Windows\", \"Apple\"),\n",
    "]\n",
    "\n",
    "for word1, word2, word3 in analogies:\n",
    "    try:\n",
    "        result = wv_pretrained.most_similar(positive=[word1, word3], negative=[word2], topn=5)\n",
    "        print(f\"{word1} - {word2} + {word3} ≈ {result[0][0]}\")\n",
    "        for similar_word, similarity in result:\n",
    "            print(f\"  {similar_word}: {similarity:.4f}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"One of the words '{word1}', '{word2}', or '{word3}' is not in the vocabulary: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
