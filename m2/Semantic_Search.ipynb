{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-13T19:05:18.573205Z","iopub.status.busy":"2024-10-13T19:05:18.572818Z","iopub.status.idle":"2024-10-13T19:05:18.959539Z","shell.execute_reply":"2024-10-13T19:05:18.958612Z","shell.execute_reply.started":"2024-10-13T19:05:18.573166Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/nlp-m2-models/final_trained_model/trained_model/config.json\n","/kaggle/input/nlp-m2-models/final_trained_model/trained_model/README.md\n","/kaggle/input/nlp-m2-models/final_trained_model/trained_model/tokenizer.json\n","/kaggle/input/nlp-m2-models/final_trained_model/trained_model/tokenizer_config.json\n","/kaggle/input/nlp-m2-models/final_trained_model/trained_model/sentence_bert_config.json\n","/kaggle/input/nlp-m2-models/final_trained_model/trained_model/config_sentence_transformers.json\n","/kaggle/input/nlp-m2-models/final_trained_model/trained_model/model.safetensors\n","/kaggle/input/nlp-m2-models/final_trained_model/trained_model/modules.json\n","/kaggle/input/nlp-m2-models/final_trained_model/trained_model/special_tokens_map.json\n","/kaggle/input/nlp-m2-models/final_trained_model/trained_model/sentencepiece.bpe.model\n","/kaggle/input/nlp-m2-models/final_trained_model/trained_model/1_Pooling/config.json\n","/kaggle/input/nlp-m2-models/final_trained_model/final_trained_model/config.json\n","/kaggle/input/nlp-m2-models/final_trained_model/final_trained_model/README.md\n","/kaggle/input/nlp-m2-models/final_trained_model/final_trained_model/tokenizer.json\n","/kaggle/input/nlp-m2-models/final_trained_model/final_trained_model/tokenizer_config.json\n","/kaggle/input/nlp-m2-models/final_trained_model/final_trained_model/sentence_bert_config.json\n","/kaggle/input/nlp-m2-models/final_trained_model/final_trained_model/config_sentence_transformers.json\n","/kaggle/input/nlp-m2-models/final_trained_model/final_trained_model/model.safetensors\n","/kaggle/input/nlp-m2-models/final_trained_model/final_trained_model/modules.json\n","/kaggle/input/nlp-m2-models/final_trained_model/final_trained_model/special_tokens_map.json\n","/kaggle/input/nlp-m2-models/final_trained_model/final_trained_model/sentencepiece.bpe.model\n","/kaggle/input/nlp-m2-models/final_trained_model/final_trained_model/1_Pooling/config.json\n","/kaggle/input/nlp-m2-models/best_model/best_model/config.json\n","/kaggle/input/nlp-m2-models/best_model/best_model/model.safetensors\n","/kaggle/input/nlp-m2-oct-2024/sample_submission.csv\n","/kaggle/input/nlp-m2-oct-2024/train.csv\n","/kaggle/input/nlp-m2-oct-2024/test.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-12T08:43:16.705615Z","iopub.status.busy":"2024-10-12T08:43:16.704695Z","iopub.status.idle":"2024-10-12T08:43:31.456530Z","shell.execute_reply":"2024-10-12T08:43:31.455370Z","shell.execute_reply.started":"2024-10-12T08:43:16.705560Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting sentence_transformers\n","  Downloading sentence_transformers-3.2.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.45.1)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.4)\n","Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.4.0)\n","Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.14.1)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.25.1)\n","Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (10.3.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.15.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.6.1)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.5.15)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.20.0)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence_transformers) (3.1.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.8.30)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n","Downloading sentence_transformers-3.2.0-py3-none-any.whl (255 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.2/255.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentence_transformers\n","Successfully installed sentence_transformers-3.2.0\n"]}],"source":["!pip install sentence_transformers"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T19:11:25.381576Z","iopub.status.busy":"2024-10-13T19:11:25.380691Z","iopub.status.idle":"2024-10-13T19:11:29.856259Z","shell.execute_reply":"2024-10-13T19:11:29.855390Z","shell.execute_reply.started":"2024-10-13T19:11:25.381534Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","from transformers import AutoTokenizer\n","\n","def preprocess_test_data(csv_file):\n","    # Load the CSV file\n","    df = pd.read_csv(csv_file)\n","    \n","    # Initialize the tokenizer\n","    tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n","    \n","    # Tokenize the text pairs\n","    encoded_data = []\n","    for _, row in df.iterrows():\n","        text_a = row['text_a']\n","        text_b = row['text_b']\n","        \n","        # Handle list-like strings in text_a\n","        if isinstance(text_a, str) and text_a.startswith('[') and text_a.endswith(']'):\n","            try:\n","                text_a_list = eval(text_a)\n","                text_a = text_a_list[0] if isinstance(text_a_list, list) else text_a\n","            except (ValueError, SyntaxError):\n","                # If parsing fails, use the original string\n","                pass\n","        \n","        encoding = tokenizer.encode_plus(\n","            text_a,\n","            text_b,\n","            add_special_tokens=True,\n","            max_length=512,\n","            padding='max_length',\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_tensors='pt'\n","        )\n","        \n","        encoded_data.append({\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'token_type_ids': encoding['token_type_ids'].flatten(),\n","        })\n","    \n","    return encoded_data, df\n","\n","# Usage:\n","# test_data, original_df = preprocess_test_data('test.csv')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T19:11:32.958803Z","iopub.status.busy":"2024-10-13T19:11:32.957944Z","iopub.status.idle":"2024-10-13T19:11:32.969256Z","shell.execute_reply":"2024-10-13T19:11:32.968364Z","shell.execute_reply.started":"2024-10-13T19:11:32.958762Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","def predict_categories(model, test_data, batch_size=16):\n","    # Create a TensorDataset\n","    dataset = TensorDataset(\n","        torch.stack([item['input_ids'] for item in test_data]),\n","        torch.stack([item['attention_mask'] for item in test_data]),\n","        torch.stack([item['token_type_ids'] for item in test_data])\n","    )\n","    \n","    # Create a DataLoader\n","    dataloader = DataLoader(dataset, batch_size=batch_size)\n","    \n","    # Set the model to evaluation mode\n","    model.eval()\n","    \n","    # Move model to GPU if available\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","    \n","    # Make predictions\n","    predictions = []\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            # Move batch to the same device as the model\n","            batch = tuple(t.to(device) for t in batch)\n","            input_ids, attention_mask, token_type_ids = batch\n","            \n","            outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","            _, preds = torch.max(outputs, dim=1)\n","            predictions.extend(preds.cpu().tolist())\n","    \n","    # Convert numerical predictions to category labels\n","    category_map = {0: 'linkage', 1: 'neutral', 2: 'contradiction'}\n","    predicted_categories = [category_map[pred] for pred in predictions]\n","    \n","    return predicted_categories\n","\n","# Usage:\n","# predicted_categories = predict_categories(model, test_data)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T19:16:41.642593Z","iopub.status.busy":"2024-10-13T19:16:41.641800Z","iopub.status.idle":"2024-10-13T19:16:42.561711Z","shell.execute_reply":"2024-10-13T19:16:42.560717Z","shell.execute_reply.started":"2024-10-13T19:16:41.642553Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch import nn\n","from transformers import AutoConfig, BertModel, BertPreTrainedModel\n","from torch.utils.data import DataLoader, TensorDataset\n","import pandas as pd\n","\n","class MultiBERTForSemanticSearch(BertPreTrainedModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.bert = BertModel(config)\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","        self.classifier = nn.Linear(config.hidden_size, 3)  # 3 classes: linkage, neutral, contradiction\n","        self.init_weights()\n","    \n","    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n","        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        pooled_output = outputs[1]\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.classifier(pooled_output)\n","        \n","        if labels is not None:\n","            loss_fct = nn.CrossEntropyLoss()\n","            loss = loss_fct(logits.view(-1, 3), labels.view(-1))\n","            return loss, logits\n","        else:\n","            return logits\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-13T19:16:42.563738Z","iopub.status.busy":"2024-10-13T19:16:42.563247Z","iopub.status.idle":"2024-10-13T19:33:40.388521Z","shell.execute_reply":"2024-10-13T19:33:40.377685Z","shell.execute_reply.started":"2024-10-13T19:16:42.563703Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Predictions saved to /kaggle/working/output_predictions.csv\n"]}],"source":["from transformers import AutoConfig\n","import pandas as pd\n","\n","def run_predictions(test_csv_path, model_path, output_csv_path):\n","    # Load and preprocess test data\n","    test_data, original_df = preprocess_test_data(test_csv_path)\n","    \n","    # Load the model\n","    config = AutoConfig.from_pretrained(model_path)\n","    model = MultiBERTForSemanticSearch.from_pretrained(model_path, config=config)\n","    \n","    # Make predictions\n","    predicted_categories = predict_categories(model, test_data)\n","    \n","    # Add predictions to the original dataframe\n","    original_df['predicted_category'] = predicted_categories\n","    \n","    # Save results to CSV\n","    original_df.to_csv(output_csv_path, index=False)\n","    print(f\"Predictions saved to {output_csv_path}\")\n","\n","# Usage:\n","run_predictions('/kaggle/input/nlp-m2-oct-2024/test.csv', '/kaggle/input/nlp-m2-models/best_model/best_model', '/kaggle/working/output_predictions.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":9798411,"sourceId":86409,"sourceType":"competition"},{"datasetId":5861815,"sourceId":9617156,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
