{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-06T05:38:34.016570Z","iopub.execute_input":"2024-09-06T05:38:34.016859Z","iopub.status.idle":"2024-09-06T05:38:34.385842Z","shell.execute_reply.started":"2024-09-06T05:38:34.016827Z","shell.execute_reply":"2024-09-06T05:38:34.384924Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/stanford-question-answering-dataset/train-v1.1.json\n/kaggle/input/stanford-question-answering-dataset/dev-v1.1.json\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\n\n# Define the file paths\ntrain_path = '/kaggle/input/stanford-question-answering-dataset/train-v1.1.json'\ndev_path = '/kaggle/input/stanford-question-answering-dataset/dev-v1.1.json'\n\n# Open and load the JSON files\nwith open(train_path, \"r\") as file:\n    train = json.load(file)\n\nwith open(dev_path, \"r\") as file:\n    dev = json.load(file)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T05:38:34.387765Z","iopub.execute_input":"2024-09-06T05:38:34.388391Z","iopub.status.idle":"2024-09-06T05:38:35.468796Z","shell.execute_reply.started":"2024-09-06T05:38:34.388344Z","shell.execute_reply":"2024-09-06T05:38:35.467793Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\nfrom datasets import load_dataset, load_metric, Dataset","metadata":{"execution":{"iopub.status.busy":"2024-09-06T05:38:35.470043Z","iopub.execute_input":"2024-09-06T05:38:35.470383Z","iopub.status.idle":"2024-09-06T05:38:53.489974Z","shell.execute_reply.started":"2024-09-06T05:38:35.470350Z","shell.execute_reply":"2024-09-06T05:38:53.488993Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n\ndef preprocess_function(question, context, answer_start_char, answer_end_char):\n    inputs = tokenizer(\n        question,\n        context,\n        max_length=config[\"max_length\"],\n        truncation=\"only_second\",\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    offset = inputs.pop(\"offset_mapping\")\n    sequence_ids = inputs.sequence_ids()\n\n    context_start, context_end = -1, -1\n\n    # Add logic to find the token indices for context start and context end using `sequence_ids``.\n    for i, seq_id in enumerate(sequence_ids):\n      if seq_id==1 and context_start== -1:\n        context_start=i\n      elif seq_id != 1 and context_start != -1:\n        context_end =i\n        break\n    if context_end ==-1:\n      context_end = len(sequence_ids)\n\n\n    context_offsets = offset[context_start: context_end]\n\n    # Create a mapping of charcter index to token index.\n    charcter_pos_to_token_pos = {}\n    for token_pos, (char_start, char_end) in enumerate(context_offsets):\n        for char_pos in range(char_start, char_end):\n          charcter_pos_to_token_pos[char_pos] = token_pos+context_start\n\n    start_pos = charcter_pos_to_token_pos.get(answer_start_char, 0)\n    end_pos = charcter_pos_to_token_pos.get(\n        answer_end_char - 1,\n        0 if start_pos == 0 else config['max_length'] - 1\n    )\n\n    inputs[\"start_positions\"] = start_pos\n    inputs[\"end_positions\"] = end_pos\n\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2024-09-06T05:38:53.492574Z","iopub.execute_input":"2024-09-06T05:38:53.493634Z","iopub.status.idle":"2024-09-06T05:38:56.262209Z","shell.execute_reply.started":"2024-09-06T05:38:53.493585Z","shell.execute_reply":"2024-09-06T05:38:56.261194Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de687cf6a7b44927b3ac93ec93cd151c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc9c557a28e048cbb8c98588df954cc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08265d825daa4c29be5d94feb5bf9244"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d93694c18a3d4750b5728eae6219e2fb"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_data(examples):\n    preprocessed_examples = []\n\n    # Iterate through each article in the dataset\n    for article in examples['data']:\n        # Iterate through each paragraph in the article\n        for paragraph in article['paragraphs']:\n            context = paragraph['context']  # Extract the context text\n\n            # Iterate through each question-answer (QA) pair in the paragraph\n            for qa in paragraph['qas']:\n                question = qa['question']  # Extract the question text\n                answers = qa['answers']    # Extract the list of answers\n\n                # For each answer, get the start and end positions\n                for answer in answers:\n                    start_char = answer['answer_start']\n                    end_char = start_char + len(answer['text'])\n\n                    # Preprocess and append the example\n                    preprocessed_examples.append(preprocess_function(question, context, start_char, end_char))\n\n    return preprocessed_examples","metadata":{"execution":{"iopub.status.busy":"2024-09-06T05:38:56.263433Z","iopub.execute_input":"2024-09-06T05:38:56.263753Z","iopub.status.idle":"2024-09-06T05:38:56.270425Z","shell.execute_reply.started":"2024-09-06T05:38:56.263718Z","shell.execute_reply":"2024-09-06T05:38:56.269572Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"config = {\n    \"max_length\": 384,  # You can adjust this value based on your requirements\n    \"doc_stride\": 128,   # This is often used for splitting long contexts\n    \"batch_size\": 16,    # Adjust based on your hardware capacity\n    \"epochs\": 3,         # Number of training epochs\n    \"learning_rate\": 3e-5, # Learning rate for the optimizer\n}","metadata":{"execution":{"iopub.status.busy":"2024-09-06T05:38:56.271394Z","iopub.execute_input":"2024-09-06T05:38:56.271667Z","iopub.status.idle":"2024-09-06T05:38:56.283938Z","shell.execute_reply.started":"2024-09-06T05:38:56.271631Z","shell.execute_reply":"2024-09-06T05:38:56.283160Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"preprocessed_train_data = preprocess_data(train)\npreprocessed_dev_data = preprocess_data(dev)\n\ntrain_dataset = Dataset.from_pandas(pd.DataFrame(preprocessed_train_data))\ndev_dataset = Dataset.from_pandas(pd.DataFrame(preprocessed_dev_data))","metadata":{"execution":{"iopub.status.busy":"2024-09-06T05:38:56.285002Z","iopub.execute_input":"2024-09-06T05:38:56.285330Z","iopub.status.idle":"2024-09-06T05:41:06.512463Z","shell.execute_reply.started":"2024-09-06T05:38:56.285283Z","shell.execute_reply":"2024-09-06T05:41:06.511662Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForQuestionAnswering.from_pretrained('distilbert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2024-09-06T05:41:06.513575Z","iopub.execute_input":"2024-09-06T05:41:06.513889Z","iopub.status.idle":"2024-09-06T05:41:14.259732Z","shell.execute_reply.started":"2024-09-06T05:41:06.513857Z","shell.execute_reply":"2024-09-06T05:41:14.259012Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3ec2f0577f44ce5a84b1be570124226"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Token Level IoU\nfrom transformers import EvalPrediction\n\ndef compute_token_level_iou(eval_pred: EvalPrediction):\n\n    # Unpack the predictions and label_ids\n    predictions = eval_pred.predictions\n    labels = eval_pred.label_ids\n\n    # Convert labels to a NumPy array if it's a tuple\n    if isinstance(labels, tuple):\n        labels = np.array(labels)\n\n    # Assuming predictions are logits for start and end positions\n    # Split the predictions into start and end logits\n    start_logits, end_logits = predictions\n    # Convert logits to predicted start and end positions\n    pred_starts = np.argmax(start_logits, axis=1)\n    pred_ends = np.argmax(end_logits, axis=1)\n\n    # Extract true start and end positions from labels\n    # Assuming labels contain start and end positions\n    # Depending on how labels are structured, you might need to adjust this\n    true_starts = labels[:, 0]\n    true_ends = labels[:, 1]\n\n    # Compute IoU for each prediction\n    iou_scores = []\n    for pred_start, pred_end, true_start, true_end in zip(pred_starts, pred_ends, true_starts, true_ends):\n        # Calculate intersection\n        intersection_start = max(pred_start, true_start)\n        intersection_end = min(pred_end, true_end)\n        intersection = max(0, intersection_end - intersection_start + 1)\n\n        # Calculate union\n        union_start = min(pred_start, true_start)\n        union_end = max(pred_end, true_end)\n        union = union_end - union_start + 1\n\n        # Compute IoU\n        iou = intersection / union if union > 0 else 0.0\n        iou_scores.append(iou)\n\n    # Calculate the average IoU over all samples\n    average_iou = np.mean(iou_scores)\n\n    return {\"token_level_IoU\": average_iou}","metadata":{"execution":{"iopub.status.busy":"2024-09-06T05:41:14.260835Z","iopub.execute_input":"2024-09-06T05:41:14.261138Z","iopub.status.idle":"2024-09-06T05:41:14.270344Z","shell.execute_reply.started":"2024-09-06T05:41:14.261105Z","shell.execute_reply":"2024-09-06T05:41:14.269449Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import wandb\n\nwandb.login(key='225dc77b79b3ab5078f63b1794f235d7b2ccca9a')","metadata":{"execution":{"iopub.status.busy":"2024-09-06T05:55:17.060362Z","iopub.execute_input":"2024-09-06T05:55:17.061165Z","iopub.status.idle":"2024-09-06T05:55:17.846915Z","shell.execute_reply.started":"2024-09-06T05:55:17.061124Z","shell.execute_reply":"2024-09-06T05:55:17.845907Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    run_name='Question_Answering',\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=1,\n    weight_decay=0.01,\n)\n\n# Initialize the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=dev_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_token_level_iou)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T05:55:52.586898Z","iopub.execute_input":"2024-09-06T05:55:52.587638Z","iopub.status.idle":"2024-09-06T05:55:52.626132Z","shell.execute_reply.started":"2024-09-06T05:55:52.587592Z","shell.execute_reply":"2024-09-06T05:55:52.625154Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T05:55:57.092950Z","iopub.execute_input":"2024-09-06T05:55:57.093347Z","iopub.status.idle":"2024-09-06T06:30:10.120179Z","shell.execute_reply.started":"2024-09-06T05:55:57.093308Z","shell.execute_reply":"2024-09-06T06:30:10.119259Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwangdeismail\u001b[0m (\u001b[33mwangdeismail-mpstme\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011114631533332107, max=1.0â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00454cbf82c349bdbe78cd0e2122d51f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.9 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240906_055558-dzu6dt9p</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/wangdeismail-mpstme/huggingface/runs/dzu6dt9p' target=\"_blank\">Question_Answering</a></strong> to <a href='https://wandb.ai/wangdeismail-mpstme/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/wangdeismail-mpstme/huggingface' target=\"_blank\">https://wandb.ai/wangdeismail-mpstme/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/wangdeismail-mpstme/huggingface/runs/dzu6dt9p' target=\"_blank\">https://wandb.ai/wangdeismail-mpstme/huggingface/runs/dzu6dt9p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5475' max='5475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5475/5475 33:52, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Token Level Iou</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.235500</td>\n      <td>1.254838</td>\n      <td>0.500000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=5475, training_loss=1.538253870576484, metrics={'train_runtime': 2051.7759, 'train_samples_per_second': 42.694, 'train_steps_per_second': 2.668, 'total_flos': 8583810682277376.0, 'train_loss': 1.538253870576484, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Inference pipeline\n\ndef answer_question(question, context):\n    # Check the device of the model\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n\n    # Prepare inputs and move to the correct device\n    inputs = tokenizer(question, context, return_tensors='pt').to(device)\n\n    with torch.no_grad():\n        outputs = model(**inputs)\n\n    answer_start = torch.argmax(outputs.start_logits)\n    answer_end = torch.argmax(outputs.end_logits) + 1\n\n    answer = tokenizer.convert_tokens_to_string(\n        tokenizer.convert_ids_to_tokens(inputs.input_ids[0][answer_start:answer_end])\n    )\n\n    return answer\n\n# Example question\nquestion = \"What is the capital of France?\"\ncontext = \"France is a country in Europe. The capital of France is Paris.\"\nprint(answer_question(question, context))","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:30:10.121959Z","iopub.execute_input":"2024-09-06T06:30:10.122243Z","iopub.status.idle":"2024-09-06T06:30:10.158297Z","shell.execute_reply.started":"2024-09-06T06:30:10.122211Z","shell.execute_reply":"2024-09-06T06:30:10.157109Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"paris\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.save_model()  # Save the model to a specific directory\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:31:47.754744Z","iopub.execute_input":"2024-09-06T06:31:47.755701Z","iopub.status.idle":"2024-09-06T06:31:48.383536Z","shell.execute_reply.started":"2024-09-06T06:31:47.755658Z","shell.execute_reply":"2024-09-06T06:31:48.382426Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import os\n\nfor dirname, _, filenames in os.walk('./results'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:35:09.228181Z","iopub.execute_input":"2024-09-06T06:35:09.228618Z","iopub.status.idle":"2024-09-06T06:35:09.252025Z","shell.execute_reply.started":"2024-09-06T06:35:09.228580Z","shell.execute_reply":"2024-09-06T06:35:09.251109Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"./results/model.safetensors\n./results/vocab.txt\n./results/tokenizer_config.json\n./results/training_args.bin\n./results/config.json\n./results/tokenizer.json\n./results/special_tokens_map.json\n./results/runs/Sep06_05-41-14_eab0a071fa89/events.out.tfevents.1725601277.eab0a071fa89.37.0\n./results/runs/Sep06_05-55-52_eab0a071fa89/events.out.tfevents.1725602158.eab0a071fa89.37.1\n./results/checkpoint-5475/model.safetensors\n./results/checkpoint-5475/vocab.txt\n./results/checkpoint-5475/tokenizer_config.json\n./results/checkpoint-5475/training_args.bin\n./results/checkpoint-5475/config.json\n./results/checkpoint-5475/tokenizer.json\n./results/checkpoint-5475/trainer_state.json\n./results/checkpoint-5475/rng_state.pth\n./results/checkpoint-5475/special_tokens_map.json\n./results/checkpoint-5475/optimizer.pt\n./results/checkpoint-5475/scheduler.pt\n./results/checkpoint-1500/model.safetensors\n./results/checkpoint-1500/vocab.txt\n./results/checkpoint-1500/tokenizer_config.json\n./results/checkpoint-1500/training_args.bin\n./results/checkpoint-1500/config.json\n./results/checkpoint-1500/tokenizer.json\n./results/checkpoint-1500/trainer_state.json\n./results/checkpoint-1500/rng_state.pth\n./results/checkpoint-1500/special_tokens_map.json\n./results/checkpoint-1500/optimizer.pt\n./results/checkpoint-1500/scheduler.pt\n./results/checkpoint-4000/model.safetensors\n./results/checkpoint-4000/vocab.txt\n./results/checkpoint-4000/tokenizer_config.json\n./results/checkpoint-4000/training_args.bin\n./results/checkpoint-4000/config.json\n./results/checkpoint-4000/tokenizer.json\n./results/checkpoint-4000/trainer_state.json\n./results/checkpoint-4000/rng_state.pth\n./results/checkpoint-4000/special_tokens_map.json\n./results/checkpoint-4000/optimizer.pt\n./results/checkpoint-4000/scheduler.pt\n./results/checkpoint-500/model.safetensors\n./results/checkpoint-500/vocab.txt\n./results/checkpoint-500/tokenizer_config.json\n./results/checkpoint-500/training_args.bin\n./results/checkpoint-500/config.json\n./results/checkpoint-500/tokenizer.json\n./results/checkpoint-500/trainer_state.json\n./results/checkpoint-500/rng_state.pth\n./results/checkpoint-500/special_tokens_map.json\n./results/checkpoint-500/optimizer.pt\n./results/checkpoint-500/scheduler.pt\n./results/checkpoint-1000/model.safetensors\n./results/checkpoint-1000/vocab.txt\n./results/checkpoint-1000/tokenizer_config.json\n./results/checkpoint-1000/training_args.bin\n./results/checkpoint-1000/config.json\n./results/checkpoint-1000/tokenizer.json\n./results/checkpoint-1000/trainer_state.json\n./results/checkpoint-1000/rng_state.pth\n./results/checkpoint-1000/special_tokens_map.json\n./results/checkpoint-1000/optimizer.pt\n./results/checkpoint-1000/scheduler.pt\n./results/checkpoint-2500/model.safetensors\n./results/checkpoint-2500/vocab.txt\n./results/checkpoint-2500/tokenizer_config.json\n./results/checkpoint-2500/training_args.bin\n./results/checkpoint-2500/config.json\n./results/checkpoint-2500/tokenizer.json\n./results/checkpoint-2500/trainer_state.json\n./results/checkpoint-2500/rng_state.pth\n./results/checkpoint-2500/special_tokens_map.json\n./results/checkpoint-2500/optimizer.pt\n./results/checkpoint-2500/scheduler.pt\n./results/checkpoint-2000/model.safetensors\n./results/checkpoint-2000/vocab.txt\n./results/checkpoint-2000/tokenizer_config.json\n./results/checkpoint-2000/training_args.bin\n./results/checkpoint-2000/config.json\n./results/checkpoint-2000/tokenizer.json\n./results/checkpoint-2000/trainer_state.json\n./results/checkpoint-2000/rng_state.pth\n./results/checkpoint-2000/special_tokens_map.json\n./results/checkpoint-2000/optimizer.pt\n./results/checkpoint-2000/scheduler.pt\n./results/checkpoint-4500/model.safetensors\n./results/checkpoint-4500/vocab.txt\n./results/checkpoint-4500/tokenizer_config.json\n./results/checkpoint-4500/training_args.bin\n./results/checkpoint-4500/config.json\n./results/checkpoint-4500/tokenizer.json\n./results/checkpoint-4500/trainer_state.json\n./results/checkpoint-4500/rng_state.pth\n./results/checkpoint-4500/special_tokens_map.json\n./results/checkpoint-4500/optimizer.pt\n./results/checkpoint-4500/scheduler.pt\n./results/checkpoint-5000/model.safetensors\n./results/checkpoint-5000/vocab.txt\n./results/checkpoint-5000/tokenizer_config.json\n./results/checkpoint-5000/training_args.bin\n./results/checkpoint-5000/config.json\n./results/checkpoint-5000/tokenizer.json\n./results/checkpoint-5000/trainer_state.json\n./results/checkpoint-5000/rng_state.pth\n./results/checkpoint-5000/special_tokens_map.json\n./results/checkpoint-5000/optimizer.pt\n./results/checkpoint-5000/scheduler.pt\n./results/checkpoint-3000/model.safetensors\n./results/checkpoint-3000/vocab.txt\n./results/checkpoint-3000/tokenizer_config.json\n./results/checkpoint-3000/training_args.bin\n./results/checkpoint-3000/config.json\n./results/checkpoint-3000/tokenizer.json\n./results/checkpoint-3000/trainer_state.json\n./results/checkpoint-3000/rng_state.pth\n./results/checkpoint-3000/special_tokens_map.json\n./results/checkpoint-3000/optimizer.pt\n./results/checkpoint-3000/scheduler.pt\n./results/checkpoint-3500/model.safetensors\n./results/checkpoint-3500/vocab.txt\n./results/checkpoint-3500/tokenizer_config.json\n./results/checkpoint-3500/training_args.bin\n./results/checkpoint-3500/config.json\n./results/checkpoint-3500/tokenizer.json\n./results/checkpoint-3500/trainer_state.json\n./results/checkpoint-3500/rng_state.pth\n./results/checkpoint-3500/special_tokens_map.json\n./results/checkpoint-3500/optimizer.pt\n./results/checkpoint-3500/scheduler.pt\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}